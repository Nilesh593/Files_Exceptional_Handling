{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1ccb45-268f-4574-907d-cbf33dad5c55",
   "metadata": {},
   "source": [
    "## 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12761d35-2bef-40cf-8e49-6f40199431ef",
   "metadata": {},
   "source": [
    "Scenarios Where Multithreading is Preferable:\n",
    "I/O-bound Tasks:\n",
    "\n",
    "When tasks involve a lot of waiting for external resources, such as reading from or writing to files, network communication, or database access, multithreading is preferable. This is because threads can easily switch between tasks while waiting for I/O operations to complete.\n",
    "Example: A web server handling multiple client requests or a program downloading data from multiple URLs simultaneously.\n",
    "Shared Memory:\n",
    "\n",
    "If tasks need to communicate frequently or share data, multithreading is ideal because threads operate in the same memory space. This allows easy data sharing without the need for complex inter-process communication mechanisms.\n",
    "Example: A GUI application where multiple components (like a progress bar and a file loader) need to share state and work together smoothly.\n",
    "Low Overhead:\n",
    "\n",
    "Threads are lightweight compared to processes, so if the task involves relatively light workloads and doesn’t require high CPU usage, multithreading introduces less overhead in terms of memory and resource usage.\n",
    "Example: Lightweight background tasks like monitoring or logging in an application.\n",
    "Limited CPU Cores:\n",
    "\n",
    "When working on a system with fewer CPU cores or when the task doesn't benefit much from parallel processing, multithreading is a better fit. It helps avoid unnecessary overhead from spawning multiple processes.\n",
    "Scenarios Where Multiprocessing is Preferable:\n",
    "CPU-bound Tasks:\n",
    "\n",
    "If the tasks are computationally intensive and require heavy processing power (e.g., complex calculations, machine learning training, large data processing), multiprocessing is preferable. It takes full advantage of multiple CPU cores, allowing true parallelism.\n",
    "Example: Image or video processing, scientific simulations, and large-scale data analysis.\n",
    "Global Interpreter Lock (GIL) Limitation:\n",
    "\n",
    "In Python, the Global Interpreter Lock (GIL) prevents multiple threads from executing Python bytecode simultaneously. This means that even multithreaded programs might not fully utilize CPU cores for CPU-bound tasks. Multiprocessing avoids this by creating separate processes, each with its own Python interpreter and GIL.\n",
    "Example: Tasks like matrix multiplications, numerical computations, or cryptography where raw CPU performance matters.\n",
    "Process Isolation:\n",
    "\n",
    "If tasks need to be run in isolated environments where their failure should not impact others, multiprocessing is safer. Each process runs independently, with its own memory space, preventing memory corruption or data inconsistency.\n",
    "Example: Running different machine learning models in parallel or sandboxing tasks where failures must be isolated.\n",
    "Parallelism Across Multiple Cores:\n",
    "\n",
    "On systems with multiple CPU cores, multiprocessing allows true parallelism, where each process can run simultaneously on different cores without being constrained by the GIL.\n",
    "Example: Running multiple simulations or tasks that can be divided into independent subtasks, such as web scraping across multiple URLs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5f091-05be-4fed-9559-45089a6ca669",
   "metadata": {},
   "source": [
    "## 2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f4d8d-a9f2-443d-beb4-f6e57533bfdd",
   "metadata": {},
   "source": [
    "A **process pool** is a collection of pre-created worker processes that are used to handle multiple tasks concurrently. Instead of creating a new process for each task, the process pool reuses existing processes, reducing the overhead associated with creating and destroying processes repeatedly.\r\n",
    "\r\n",
    "### How a Process Pool Helps Manage Multiple Processes Efficiently:\r\n",
    "\r\n",
    "1. **Resource Management**: By reusing processes, it minimizes the cost of frequently creating and destroying processes, which can be resource-intensive.\r\n",
    "   \r\n",
    "2. **Task Distribution**: Tasks are distributed among the processes in the pool, ensuring balanced load management. This makes it easier to parallelize work across multiple CPU cores.\r\n",
    "\r\n",
    "3. **Concurrency Control**: You can limit the number of concurrent processes by specifying the pool size, allowing better control over system resources.\r\n",
    "\r\n",
    "4. **Simplified API**: The process pool abstracts the complexities of managing multiple processes. You just submit tasks, and the pool handles execution, scheduling, and load balancing automatically.\r\n",
    "\r\n",
    "5. **Efficiency in Parallel Execution**: It enhances performance for CPU-bound tasks by leveraging multiple processors and ensuring parallel execution of independent tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf8e0d-13b5-480d-94d4-fb5ffa216e77",
   "metadata": {},
   "source": [
    "## 3. Explain what multiprocessing is and why it is used in Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ca4c4-6e91-4a49-a5c1-668a9be2edb9",
   "metadata": {},
   "source": [
    "**Multiprocessing** is a technique that allows a program to run multiple processes simultaneously, each with its own memory space and system resources. Unlike multithreading, where threads share the same memory, multiprocessing involves the creation of separate processes that can run in parallel, fully utilizing multiple CPU cores.\r\n",
    "\r\n",
    "### Why Multiprocessing is Used in Python:\r\n",
    "\r\n",
    "1. **Bypassing the Global Interpreter Lock (GIL)**: Python's **GIL** prevents multiple threads from executing Python bytecode simultaneously in a single process. This limits the effectiveness of multithreading in CPU-bound tasks. **Multiprocessing**, however, creates separate processes, each with its own Python interpreter and GIL, allowing true parallelism on multiple CPU cores.\r\n",
    "\r\n",
    "2. **Parallel Execution for CPU-bound Tasks**: For tasks that require a lot of CPU power (like data processing, machine learning, or mathematical computations), multiprocessing is ideal because it can distribute the workload across multiple processors, improving performance.\r\n",
    "\r\n",
    "3. **Isolation**: Since each process runs independently with its own memory space, multiprocessing provides better isolation, reducing issues like race conditions that can occur in multithreading.\r\n",
    "\r\n",
    "4. **Improved Performance**: By leveraging multiple cores, multiprocessing can significantly speed up programs, especially when handling large datasets or performing computationally expensive operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d57ba-ef28-4d8c-a83f-e501953806b9",
   "metadata": {},
   "source": [
    "## 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5a3ac-0fd7-4252-9c95-392d25971bf6",
   "metadata": {},
   "source": [
    "Here's a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. To prevent race conditions, I've used a `threading.Lock` to ensure that only one thread can modify the list at a time.phat only one thread can modify the list at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc2e06d-b410-481a-912f-e4b5365c1533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 to the list\n",
      "Removed 0 from the list\n",
      "Added 1 to the list\n",
      "Removed 1 from the list\n",
      "Added 2 to the list\n",
      "Added 3 to the list\n",
      "Removed 2 from the list\n",
      "Added 4 to the list\n",
      "Removed 3 from the list\n",
      "Added 5 to the list\n",
      "Added 6 to the list\n",
      "Removed 4 from the list\n",
      "Added 7 to the list\n",
      "Removed 5 from the list\n",
      "Added 8 to the list\n",
      "Added 9 to the list\n",
      "Removed 6 from the list\n",
      "Removed 7 from the list\n",
      "Removed 8 from the list\n",
      "Removed 9 from the list\n",
      "Final list: []\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared list\n",
    "shared_list = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "def add_to_list():\n",
    "    for i in range(10):\n",
    "        time.sleep(0.1)  # Simulating work\n",
    "        with lock:\n",
    "            shared_list.append(i)\n",
    "            print(f\"Added {i} to the list\")\n",
    "\n",
    "def remove_from_list():\n",
    "    for i in range(10):\n",
    "        time.sleep(0.15)  # Simulating work\n",
    "        with lock:\n",
    "            if shared_list:\n",
    "                removed = shared_list.pop(0)\n",
    "                print(f\"Removed {removed} from the list\")\n",
    "\n",
    "# Create threads\n",
    "t1 = threading.Thread(target=add_to_list)\n",
    "t2 = threading.Thread(target=remove_from_list)\n",
    "\n",
    "# Start threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Wait for both threads to finish\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(\"Final list:\", shared_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539888f9-e04d-4413-bcc2-89a6762a6ef6",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation:\n",
    "\n",
    "- **Shared List**: The `shared_list` is a common list that both threads modify.\n",
    "- **Lock (`threading.Lock`)**: The `lock` ensures that only one thread can add or remove elements at any given time, preventing race conditions.\n",
    "- **Two Threads**: \n",
    "  - The `add_to_list` thread adds numbers from 0 to 9 into the shared list.\n",
    "  - The `remove_from_list` thread removes numbers from the list if there are elements present.\n",
    "- **Time Delays (`time.sleep`)**: The `sleep` calls simulate some work being done and create conditions where threads might try to access the list simultaneously.\n",
    "- **Using `with lock`**: This is a context manager that automatically acquires and releases the lock, ensuring thread-safe operations.\n",
    "\n",
    "This approach prevents race conditions by making sure that only one thread can modify the list at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c1ad5-f246-47b5-b0c6-b4b1f8037184",
   "metadata": {},
   "source": [
    "## 5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ee278-5986-40e6-bc34-cc30510d86bd",
   "metadata": {},
   "source": [
    "In Python, sharing data between threads and processes can lead to race conditions and inconsistent data if not handled properly. Various methods and tools are available to ensure that data sharing is done safely in concurrent environments.\n",
    "\n",
    "### 1. **Methods and Tools for Sharing Data Between Threads**\n",
    "\n",
    "Since threads share the same memory space, synchronization tools are necessary to avoid race conditions:\n",
    "\n",
    "- **`threading.Lock`**:\n",
    "  - A **Lock** ensures that only one thread can access a shared resource at a time.\n",
    "  - Threads must acquire the lock before modifying shared data and release it afterward.\n",
    "  \n",
    "  Example:\n",
    "  ```python\n",
    "  lock = threading.Lock()\n",
    "  with lock:\n",
    "      # Safe access to shared resource\n",
    "  ```\n",
    "\n",
    "- **`threading.RLock`**:\n",
    "  - A **Reentrant Lock** (RLock) is a lock that can be acquired multiple times by the same thread without causing a deadlock.\n",
    "  - Useful in cases where a thread needs to acquire the lock again before releasing it.\n",
    "\n",
    "- **`threading.Condition`**:\n",
    "  - A **Condition** is used to allow threads to wait for certain conditions to be met before continuing. It's useful when multiple threads need to coordinate the use of a shared resource.\n",
    "  - Condition works with a Lock to notify waiting threads when the resource becomes available.\n",
    "\n",
    "- **`threading.Semaphore`**:\n",
    "  - A **Semaphore** limits the number of threads that can access a shared resource at the same time.\n",
    "  - For example, a `Semaphore(3)` allows only three threads to access the resource concurrently.\n",
    "\n",
    "- **`threading.Event`**:\n",
    "  - An **Event** is a simple flag that threads can set or clear to signal the occurrence of an event, helping to synchronize actions between threads.\n",
    "\n",
    "### 2. **Methods and Tools for Sharing Data Between Processes**\n",
    "\n",
    "Unlike threads, processes in Python have separate memory spaces, so they cannot directly share data. Python's `multiprocessing` module provides several mechanisms to safely share data between processes:\n",
    "\n",
    "- **`multiprocessing.Queue`**:\n",
    "  - A **Queue** allows processes to exchange data in a thread-safe manner.\n",
    "  - It uses a FIFO (First In, First Out) structure and can be shared between processes without the need for locks.\n",
    "  \n",
    "  Example:\n",
    "  ```python\n",
    "  from multiprocessing import Queue\n",
    "  q = Queue()\n",
    "  q.put(data)\n",
    "  data = q.get()\n",
    "  ```\n",
    "\n",
    "- **`multiprocessing.Pipe`**:\n",
    "  - A **Pipe** is a communication channel between two processes.\n",
    "  - Pipes are two-way (duplex) communication structures where data can flow between processes in either direction.\n",
    "\n",
    "- **`multiprocessing.Manager`**:\n",
    "  - A **Manager** provides shared objects like lists, dictionaries, and other data types that can be safely accessed by multiple processes.\n",
    "  - For example, a manager can create a list that can be modified by different processes.\n",
    "\n",
    "  Example:\n",
    "  ```python\n",
    "  from multiprocessing import Manager\n",
    "  manager = Manager()\n",
    "  shared_list = manager.list()\n",
    "  ```\n",
    "\n",
    "- **`multiprocessing.Value` and `multiprocessing.Array`**:\n",
    "  - These provide a way to share simple data types (like integers or floats) and arrays between processes.\n",
    "  - They allow controlled, synchronized access to data by using shared memory.\n",
    "\n",
    "  Example:\n",
    "  ```python\n",
    "  from multiprocessing import Value\n",
    "  shared_value = Value('i', 0)  # 'i' means integer\n",
    "  ```\n",
    "\n",
    "### 3. **Higher-Level Abstractions**\n",
    "\n",
    "- **`concurrent.futures` module**:\n",
    "  - This module provides high-level interfaces for managing threads (`ThreadPoolExecutor`) and processes (`ProcessPoolExecutor`).\n",
    "  - It abstracts the lower-level details of managing threads and processes and allows sharing data safely with built-in mechanisms to handle results and exceptions.\n",
    "\n",
    "  Example:\n",
    "  ```python\n",
    "  from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "  with ThreadPoolExecutor() as executor:\n",
    "      results = executor.map(some_function, data_list)\n",
    "  ```\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Between Threads**:\n",
    "  - Tools: `Lock`, `RLock`, `Condition`, `Semaphore`, `Event`.\n",
    "  - Threads share the same memory space, so these synchronization tools help ensure thread-safe access to shared data.\n",
    "\n",
    "- **Between Processes**:\n",
    "  - Tools: `Queue`, `Pipe`, `Manager`, `Value`, `Array`.\n",
    "  - Processes have separate memory spaces, so mechanisms like queues and shared objects provided by `multiprocessing` are necessary for safely sharing data.\n",
    "\n",
    "Each tool has its own specific use case, and choosing the right one depends on whether you're dealing with threads or processes and the complexity of the data being shared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b120582-9a6f-4ad7-bbb6-4389baa9a608",
   "metadata": {},
   "source": [
    "## 6. Discuss why it's crucial to handle exceptions in concurrent programs and the techniques available for doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4195a9-e528-48ef-9559-d26f92374471",
   "metadata": {},
   "source": [
    "### Why Handling Exceptions in Concurrent Programs is Crucial\r\n",
    "\r\n",
    "1. **Preventing Application Crashes**:\r\n",
    "   - In concurrent programs (using threads or processes), an unhandled exception in one thread or process can cause the entire program or other tasks to fail, resulting in an application crash. Proper exception handling ensures that individual tasks can fail without bringing down the entire application.\r\n",
    "\r\n",
    "2. **Ensuring Task Completion**:\r\n",
    "   - Exceptions can disrupt the normal flow of execution, leaving tasks incomplete or in an inconsistent state. In a concurrent system, this can lead to missed deadlines, incomplete results, or improper task sequencing. Handling exceptions ensures tasks can gracefully recover or retry as needed.\r\n",
    "\r\n",
    "3. **Avoiding Resource Leaks**:\r\n",
    "   - If exceptions are not handled, resources like file handles, network connections, or memory may not be properly released, leading to resource leaks. This can degrade the performance of the program over time and potentially cause system-level issues.\r\n",
    "\r\n",
    "4. **Maintaining Data Integrity**:\r\n",
    "   - In concurrent programs, multiple tasks might be working on shared data. If an exception occurs without being handled, it can leave shared resources or data in an inconsistent state, leading to race conditions, deadlocks, or incorrect data.\r\n",
    "   \r\n",
    "5. **Debugging and Monitoring**:\r\n",
    "   - Proper exception handling allows developers to log or trace the source of errors in concurrent programs. This is critical for debugging complex systems where multiple threads or processes are running at the same time, making it harder to track the root cause of an issue.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Techniques for Handling Exceptions in Concurrent Programs\r\n",
    "\r\n",
    "#### 1. **Try-Except Blocks in Threads or Processes**:\r\n",
    "   - A basic approach is to wrap the concurrent task’s code in a `try-except` block. This ensures that exceptions are caught and can be handled appropriately.\r\n",
    "   \r\n",
    "   Example for a thread:\r\n",
    "   ```python\r\n",
    "   import threading\r\n",
    "\r\n",
    "   def task():\r\n",
    "       try:\r\n",
    "           # Task logic here\r\n",
    "           1 / 0  # Simulating an exception\r\n",
    "       except Exception as e:\r\n",
    "           print(f\"Exception in thread: {e}\")\r\n",
    "\r\n",
    "   t = threading.Thread(target=task)\r\n",
    "   t.start()\r\n",
    "   t.join()\r\n",
    "   ```\r\n",
    "\r\n",
    "   Similarly, you can use the same approach in a multiprocessing task.\r\n",
    "\r\n",
    "#### 2. **Using `concurrent.futures` for Automatic Exception Propagation**:\r\n",
    "   - The `concurrent.futures` module (`ThreadPoolExecutor` or `ProcessPoolExecutor`) automatically propagates exceptions raised by threads or processes. You can catch these exceptions when you retrieve the results from the future objects.\r\n",
    "\r\n",
    "   Example:\r\n",
    "   ```python\r\n",
    "   from concurrent.futures import ThreadPoolExecutor\r\n",
    "\r\n",
    "   def task(n):\r\n",
    "       return 1 / n\r\n",
    "\r\n",
    "   with ThreadPoolExecutor() as executor:\r\n",
    "       futures = [executor.submit(task, n) for n in [1, 0, 2]]\r\n",
    "       for future in futures:\r\n",
    "           try:\r\n",
    "               result = future.result()  # Will raise if there's an exception\r\n",
    "               print(f\"Result: {result}\")\r\n",
    "           except Exception as e:\r\n",
    "               print(f\"Exception caught: {e}\")\r\n",
    "   ```\r\n",
    "\r\n",
    "   - In this example, the exception from the division by zero will be propagated when `future.result()` is called, and can be handled in the `except` block.\r\n",
    "\r\n",
    "#### 3. **Threading and `sys.excepthook` for Unhandled Exceptions**:\r\n",
    "   - For multithreading, Python provides a way to handle uncaught exceptions globally using `sys.excepthook`. This can be helpful if you don’t catch exceptions in individual threads.\r\n",
    "   \r\n",
    "   Example:\r\n",
    "   ```python\r\n",
    "   import threading\r\n",
    "   import sys\r\n",
    "\r\n",
    "   def handle_uncaught_exception(exc_type, exc_value, exc_traceback):\r\n",
    "       print(f\"Uncaught exception: {exc_value}\")\r\n",
    "\r\n",
    "   sys.excepthook = handle_uncaught_exception\r\n",
    "\r\n",
    "   def task():\r\n",
    "       raise ValueError(\"Something went wrong\")\r\n",
    "\r\n",
    "   t = threading.Thread(target=task)\r\n",
    "   t.start()\r\n",
    "   t.join()\r\n",
    "   ```\r\n",
    "\r\n",
    "#### 4. **Using Queues to Propagate Exceptions**:\r\n",
    "   - For more custom handling, especially in `multiprocessing`, you can use `multiprocessing.Queue` to propagate exceptions back to the main thread or process.\r\n",
    "   \r\n",
    "   Example:\r\n",
    "   ```python\r\n",
    "   import multiprocessing\r\n",
    "\r\n",
    "   def worker(q):\r\n",
    "       try:\r\n",
    "           raise ValueError(\"Error in process\")\r\n",
    "       except Exception as e:\r\n",
    "           q.put(e)\r\n",
    "\r\n",
    "   if __name__ == \"__main__\":\r\n",
    "       q = multiprocessing.Queue()\r\n",
    "       p = multiprocessing.Process(target=worker, args=(q,))\r\n",
    "       p.start()\r\n",
    "       p.join()\r\n",
    "       if not q.empty():\r\n",
    "           print(f\"Exception in process: {q.get()}\")\r\n",
    "   ```\r\n",
    "\r\n",
    "#### 5. **Using `finally` Block for Cleanup**:\r\n",
    "   - A `finally` block ensures that resources are cleaned up properly, even if an exception occurs. This is crucial in concurrent programs to avoid resource leaks.\r\n",
    "   \r\n",
    "   Example:\r\n",
    "   ```python\r\n",
    "   def task():\r\n",
    "       try:\r\n",
    "           # Some work here\r\n",
    "           raise Exception(\"An error occurred\")\r\n",
    "       except Exception as e:\r\n",
    "           print(f\"Exception: {e}\")\r\n",
    "       finally:\r\n",
    "           print(\"Cleaning up resources\")\r\n",
    "   ```\r\n",
    "\r\n",
    "#### 6. **Graceful Shutdown and Recovery**:\r\n",
    "   - Concurrent programs should have mechanisms to gracefully handle exceptions and shut down safely. For instance, ks for resource cleanup.\r\n",
    "\r\n",
    "Effective exception handling makes concurrent programs more robust, predictable, and easier to maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2879c-2818-421b-aea8-f8b72cb70cf7",
   "metadata": {},
   "source": [
    "## 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2909df6-9638-4327-8b54-e42f2e6f47df",
   "metadata": {},
   "source": [
    "Here’s a Python program that uses a `ThreadPoolExecutor` to calculate the factorial of numbers from 1 to 10 concurrently:\n",
    "\n",
    "### Program:\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "\n",
    "# Function to calculate the factorial of a number\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "# List of numbers to calculate the factorial for\n",
    "numbers = range(1, 11)\n",
    "\n",
    "# Using ThreadPoolExecutor to manage the threads\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Map the factorial function to the list of numbers\n",
    "    results = executor.map(factorial, numbers)\n",
    "\n",
    "# Convert the results (which is an iterator) to a list and print each result\n",
    "for num, result in zip(numbers, results):\n",
    "    print(f\"Factorial of {num} is {result}\")\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **`factorial(n)`**: This function takes a number `n` and returns its factorial using Python's built-in `math.factorial()` function.\n",
    "2. **`numbers = range(1, 11)`**: A list of numbers from 1 to 10 is created for which we will calculate the factorials.\n",
    "3. **`ThreadPoolExecutor`**: This manages a pool of threads. The `executor.map(factorial, numbers)` applies the `factorial` function to each number in the list concurrently.\n",
    "4. **`results`**: The results from `executor.map` are returned as an iterator, and we print the factorials of each number by iterating over the results.\n",
    "\n",
    "### Output:\n",
    "```\n",
    "Factorial of 1 is 1\n",
    "Factorial of 2 is 2\n",
    "Factorial of 3 is 6\n",
    "Factorial of 4 is 24\n",
    "Factorial of 5 is 120\n",
    "Factorial of 6 is 720\n",
    "Factorial of 7 is 5040\n",
    "Factorial of 8 is 40320\n",
    "Factorial of 9 is 362880\n",
    "Factorial of 10 is 3628800\n",
    "```\n",
    "\n",
    "This program calculates the factorial of each number concurrently using threads, providing efficient parallel execution for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55fc4b-8019-481f-864e-ab0eeefe0102",
   "metadata": {},
   "source": [
    "## 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78794005-8136-409e-a8a5-d4bb5d179e7f",
   "metadata": {},
   "source": [
    "Here’s a Python program that uses `multiprocessing.Pool` to compute the square of numbers from 1 to 10 in parallel, and measures the time taken for this computation using different pool sizes.\r\n",
    "\r\n",
    "### Program:\r\n",
    "\r\n",
    "```python\r\n",
    "import multiprocessing\r\n",
    "import time\r\n",
    "\r\n",
    "# Function to calculate the square of a number\r\n",
    "def square(n):\r\n",
    "    return n * n\r\n",
    "\r\n",
    "# List of numbers to calculate the square for\r\n",
    "numbers = range(1, 11)\r\n",
    "\r\n",
    "# Function to measure the time taken for multiprocessing with a given pool size\r\n",
    "def compute_squares(pool_size):\r\n",
    "    start_time = time.time()  # Record the start time\r\n",
    "    \r\n",
    "    with multiprocessing.Pool(pool_size) as pool:\r\n",
    "        results = pool.map(square, numbers)\r\n",
    "    \r\n",
    "    end_time = time.time()  # Record the end time\r\n",
    "    print(f\"Pool size: {pool_size}, Time taken: {end_time - start_time:.4f} seconds, Results: {results}\")\r\n",
    "\r\n",
    "# Measure time for different pool sizes\r\n",
    "for pool_size in [2, 4, 8]:\r\n",
    "    compute_squares(pool_size)\r\n",
    "```\r\n",
    "\r\n",
    "### Explanation:\r\n",
    "\r\n",
    "1. **`square(n)`**: This function takes a number `n` and returns its square.\r\n",
    "2. **`numbers = range(1, 11)`**: A list of numbers from 1 to 10 for which we will compute the squares.\r\n",
    "3. **`compute_squares(pool_size)`**: This function creates a pool with a given number of processes (`pool_size`) and uses `pool.map` to apply the `square` function to the list of numbers. The time taken to compute the squares is measured using `time.time()`.\r\n",
    "4. **`for pool_size in [2, 4, 8]`**: We run the computation with different pool sizes (2, 4, and 8 processes) and print the time taken and the results.\r\n",
    "\r\n",
    "### Output:\r\n",
    "The program will print something like:\r\n",
    "\r\n",
    "```\r\n",
    "Pool size: 2, Time taken: 0.0145 seconds, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\r\n",
    "Pool size: 4, Time taken: 0.0137 seconds, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\r\n",
    "Pool size: 8, Time taken: 0.0142 seconds, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\r\n",
    "```\r\n",
    "\r\n",
    "### Explanation of Output:\r\n",
    "- **Pool size**: This indicates the number of processes used for the computation.\r\n",
    "- **Time taken**: This shows the time in seconds that it took to compute the squares for the numbers using the given pool size.\r\n",
    "- **Results**: The squared values of numbers from 1 to 10.\r\n",
    "\r\n",
    "This program demonstrates how using different numbers of processes impacts the performance of parallel computations in Python using `multiprocessing.Pool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c7791-eb00-4d1a-b9e6-f767b3d3708d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
